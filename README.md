**ğŸ§  DistilBERT Explainability â€” Attention & LIME**
This project demonstrates explainable AI (XAI) techniques applied to a DistilBERT sentiment-analysis model. It visualizes how the model makes decisions using attention heatmaps, LIME explanations, and faithfulness tests.

**ğŸš€ Features**
Sentiment classification using DistilBERT
Attention heatmap showing where the model focuses
LIME explanations for token-level importance
Faithfulness test by removing influential words to validate explanations
Clean, reproducible code designed for Colab

**ğŸ”§ Tech Stack**
Python
HuggingFace Transformers
PyTorch
LIME
Matplotlib / Seaborn

**ğŸ“ Workflow**
Load pretrained DistilBERT (distilbert-base-uncased-finetuned-sst-2-english)
Generate sentiment prediction
Visualize CLS-token attention
Use LIME to highlight influential words
Remove top LIME words to test robustness# Explainability_in_Sentiment_Analysis

**â–¶ï¸ How to Run**
1. Click the link to the colab.
2. Run the cells
3. observe the output. 
